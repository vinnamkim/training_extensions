{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import CocoDataset\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = \"aerial-maritime\"\n",
    "# dname = \"pklot\"\n",
    "# dname = \"d6-dice\"\n",
    "\n",
    "ann_file = f'/mnt/ssd2/sc_datasets_det/{dname}/annotations/instances_train.json'\n",
    "\n",
    "with open(ann_file, \"r\") as fp:\n",
    "    anno = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=1237, M=61\n"
     ]
    }
   ],
   "source": [
    "annots = anno[\"annotations\"]\n",
    "\n",
    "N = len(annots)\n",
    "M = max(int(N * 0.05), 1)\n",
    "print(f\"N={N}, M={M}\")\n",
    "\n",
    "random.shuffle(annots)\n",
    "\n",
    "no_set = annots[:M]\n",
    "ok_set = annots[M:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {ann[\"id\"]: ann for ann in anno[\"images\"]}\n",
    "dxdys = [np.array([1, 0]), np.array([0, 1]), np.array([1, 1])] + [-np.array([1, 0]), -np.array([0, 1]), -np.array([1, 1])]\n",
    "cat_ids = np.unique([ann[\"category_id\"] for ann in annots])\n",
    "\n",
    "def _move_bbox(ann, delta = 0.4):\n",
    "    img_w, img_h = images[ann[\"image_id\"]][\"width\"], images[ann[\"image_id\"]][\"height\"]\n",
    "        \n",
    "    x, y, w, h = ann[\"bbox\"]\n",
    "    # x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "    wh = np.array([w, h])\n",
    "\n",
    "    dxdy = random.choice(dxdys)\n",
    "    dxdy = 0.2 * wh * dxdy\n",
    "    \n",
    "    x1y1 = np.array([x, y]) + dxdy\n",
    "    x2y2 = x1y1 + wh\n",
    "\n",
    "    x1, y1 = x1y1\n",
    "    x2, y2 = x2y2\n",
    "\n",
    "    x1 = np.clip(x1, 0, img_w)\n",
    "    x2 = np.clip(x2, 0, img_w)\n",
    "    y1 = np.clip(y1, 0, img_h)\n",
    "    y2 = np.clip(y2, 0, img_h)\n",
    "\n",
    "    ann[\"bbox\"] = [x1, y1, x2 - x1, y2 - y1]\n",
    "    ann[\"noise\"] = 1\n",
    "\n",
    "def _change_label(ann):\n",
    "    id = ann[\"category_id\"]\n",
    "    new_id = random.choice(cat_ids)\n",
    "    while id == new_id:\n",
    "        new_id = random.choice(cat_ids)\n",
    "\n",
    "    ann[\"category_id\"] = id\n",
    "    ann[\"noise\"] = 2\n",
    "\n",
    "for idx, ann in enumerate(no_set):\n",
    "    if idx < M // 2:\n",
    "        _move_bbox(ann)\n",
    "    else:\n",
    "        _change_label(ann)\n",
    "\n",
    "for ann in ok_set:\n",
    "    ann[\"noise\"] = 0\n",
    "\n",
    "anno[\"annotations\"] = no_set + ok_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd2/sc_datasets_det/aerial-maritime/annotations/instances_train_noise.json\n"
     ]
    }
   ],
   "source": [
    "dir_path, fname = os.path.split(ann_file)\n",
    "name, ext = os.path.splitext(fname) \n",
    "\n",
    "new_fpath = os.path.join(dir_path, name + \"_noise\" + ext)\n",
    "\n",
    "with open(new_fpath, \"w\") as fp:\n",
    "    json.dump(anno, fp)\n",
    "    print(new_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets.builder import PIPELINES\n",
    "from mmcv.parallel import DataContainer as DC\n",
    "from mmdet.datasets.pipelines import to_tensor\n",
    "from mmdet.datasets import CocoDataset\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "img_size = (992, 736)\n",
    "img_norm_cfg = dict(mean=[0, 0, 0], std=[255, 255, 255], to_rgb=True)\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='MinIoURandomCrop',\n",
    "        min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n",
    "        min_crop_size=0.3),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        img_scale=[(992, 736), (896, 736), (1088, 736), (992, 672), (992, 800)],\n",
    "        multiscale_mode='value',\n",
    "        keep_ratio=False),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type=\"LabelNoiseBundle\"),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'noise_labels', 'anno_ids'])\n",
    "]\n",
    "\n",
    "\n",
    "@PIPELINES.register_module()\n",
    "class LabelNoiseBundle(object):\n",
    "    def __call__(self, results):\n",
    "        ann_info = results[\"ann_info\"]\n",
    "        for key in [\"noise_labels\", \"anno_ids\"]:\n",
    "            if key not in ann_info:\n",
    "                continue\n",
    "            results[key] = DC(to_tensor(ann_info[key]))\n",
    "        return results\n",
    "    \n",
    "class LabelNoiseCocoDataset(CocoDataset):\n",
    "    def __init__(self, min_size=None, *args, **kwargs):\n",
    "        super().__init__(min_size, *args, **kwargs)\n",
    "\n",
    "    def _parse_ann_info(self, img_info, ann_info):\n",
    "        \"\"\"Parse bbox and mask annotation.\n",
    "\n",
    "        Args:\n",
    "            ann_info (list[dict]): Annotation info of an image.\n",
    "            with_mask (bool): Whether to parse mask annotations.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dict containing the following keys: bboxes, bboxes_ignore,\\\n",
    "                labels, masks, seg_map. \"masks\" are raw annotations and not \\\n",
    "                decoded into binary masks.\n",
    "        \"\"\"\n",
    "        gt_bboxes = []\n",
    "        gt_labels = []\n",
    "        gt_bboxes_ignore = []\n",
    "        gt_masks_ann = []\n",
    "        noise_labels = []\n",
    "        anno_ids = []\n",
    "        for i, ann in enumerate(ann_info):\n",
    "            if ann.get('ignore', False):\n",
    "                continue\n",
    "            x1, y1, w, h = ann['bbox']\n",
    "            inter_w = max(0, min(x1 + w, img_info['width']) - max(x1, 0))\n",
    "            inter_h = max(0, min(y1 + h, img_info['height']) - max(y1, 0))\n",
    "            if inter_w * inter_h == 0:\n",
    "                continue\n",
    "            if ann['area'] <= 0 or w < 1 or h < 1:\n",
    "                continue\n",
    "            if self.min_size is not None:\n",
    "                if w < self.min_size or h < self.min_size:\n",
    "                    continue\n",
    "            if ann['category_id'] not in self.cat_ids:\n",
    "                continue\n",
    "            bbox = [x1, y1, x1 + w, y1 + h]\n",
    "            if ann.get('iscrowd', False):\n",
    "                gt_bboxes_ignore.append(bbox)\n",
    "            else:\n",
    "                gt_bboxes.append(bbox)\n",
    "                gt_labels.append(self.cat2label[ann['category_id']])\n",
    "                gt_masks_ann.append(ann.get('segmentation', None))\n",
    "                noise_labels.append(ann[\"noise\"])\n",
    "                anno_ids.append(ann[\"id\"])\n",
    "\n",
    "        if gt_bboxes:\n",
    "            gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\n",
    "            gt_labels = np.array(gt_labels, dtype=np.int64)\n",
    "        else:\n",
    "            gt_bboxes = np.zeros((0, 4), dtype=np.float32)\n",
    "            gt_labels = np.array([], dtype=np.int64)\n",
    "\n",
    "        if gt_bboxes_ignore:\n",
    "            gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\n",
    "        else:\n",
    "            gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n",
    "\n",
    "        seg_map = img_info['filename'].replace('jpg', 'png')\n",
    "\n",
    "        ann = dict(\n",
    "            bboxes=gt_bboxes,\n",
    "            labels=gt_labels,\n",
    "            bboxes_ignore=gt_bboxes_ignore,\n",
    "            masks=gt_masks_ann,\n",
    "            seg_map=seg_map,\n",
    "            noise_labels=noise_labels,\n",
    "            anno_ids=anno_ids\n",
    "        )\n",
    "\n",
    "        return ann\n",
    "\n",
    "dname = \"aerial-maritime\"\n",
    "ann_file = f'/mnt/ssd2/sc_datasets_det/{dname}/annotations/instances_train_noise.json'\n",
    "img_prefix = f'/mnt/ssd2/sc_datasets_det/{dname}/images/train'\n",
    "\n",
    "with open(ann_file, \"r\") as fp:\n",
    "    anno = json.load(fp)\n",
    "\n",
    "classes = [ele[\"name\"] for ele in anno[\"categories\"]]\n",
    "\n",
    "dataset = LabelNoiseCocoDataset(\n",
    "    ann_file=ann_file,\n",
    "    pipeline=train_pipeline,\n",
    "    classes=classes,\n",
    "    data_root=\"\",\n",
    "    img_prefix=img_prefix,\n",
    "    seg_prefix=None,\n",
    "    proposal_file=None,\n",
    "    test_mode=False,\n",
    "    filter_empty_gt=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "816d40c60b3f63b9a3caffdd17214970757f08e3cbc17f1c4de9590657d21529"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
