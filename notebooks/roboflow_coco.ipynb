{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from https://universe.roboflow.com/joseph-nelson/thermal-dogs-and-people and place it (`Thermal\\ Dogs\\ and\\ People.v6-raw-images_autoorient.coco.zip`) to the directory of this notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Thermal Dogs and People.v6-raw-images_autoorient.coco.zip\n",
      " extracting: data/README.dataset.txt  \n",
      " extracting: data/README.roboflow.txt  \n",
      "   creating: data/test/\n",
      " extracting: data/test/IMG_0002-4_jpg.rf.f40dcac951f2e9fade8717e27bec2e9e.jpg  \n",
      " extracting: data/test/IMG_0006-5_jpg.rf.7d2020803a12483f643fef278375b1aa.jpg  \n",
      " extracting: data/test/IMG_0009_jpg.rf.4843a778e5ad0a37dc9d9eca705b8234.jpg  \n",
      " extracting: data/test/IMG_0012-2_jpg.rf.33bd9fde4442b41043fe4a8c58c495f7.jpg  \n",
      " extracting: data/test/IMG_0022_jpg.rf.33d9e7f65659e9dd93443504a2ae02b4.jpg  \n",
      " extracting: data/test/IMG_0023-3_jpg.rf.14c19a106b8de318192f03c08eaf2990.jpg  \n",
      " extracting: data/test/IMG_0024-2_jpg.rf.db65a78b2faebddde52b22537b17605d.jpg  \n",
      " extracting: data/test/IMG_0027_jpg.rf.1d755a5883c8a59ab4e0c9365f8d2cbd.jpg  \n",
      " extracting: data/test/IMG_0031-2_jpg.rf.b2c3bde3147f85f775040a824397f745.jpg  \n",
      " extracting: data/test/IMG_0033-2_jpg.rf.842e45a7a0505b32d06cd7307afb2907.jpg  \n",
      " extracting: data/test/IMG_0037-2_jpg.rf.ac4431c48a93d34892dde185b6556199.jpg  \n",
      " extracting: data/test/IMG_0040-2_jpg.rf.fd02f6a30556c094f8d19531ee11ffef.jpg  \n",
      " extracting: data/test/IMG_0043-2_jpg.rf.e101b7d3f607719f72dc823b43093da1.jpg  \n",
      " extracting: data/test/IMG_0045_jpg.rf.76894f6f4a37bee7c3ed79234f5fc33e.jpg  \n",
      " extracting: data/test/IMG_0059_jpg.rf.f87f4d8727811e61871b785197c8d275.jpg  \n",
      " extracting: data/test/IMG_0060_jpg.rf.5bd7a3f676402b9eac6009531b07e493.jpg  \n",
      " extracting: data/test/IMG_0106_jpg.rf.8b99377c8156a0816488c6e96dc58497.jpg  \n",
      " extracting: data/test/IMG_0113_jpg.rf.20c0f110b5e422723d4500c73a4e276c.jpg  \n",
      " extracting: data/test/IMG_0114_jpg.rf.be82ec1d3438619add5d9d9db44f123a.jpg  \n",
      " extracting: data/test/IMG_0115_jpg.rf.0c27b2a618bd713ced15a8655f141ac9.jpg  \n",
      " extracting: data/test/_annotations.coco.json  \n",
      "   creating: data/train/\n",
      " extracting: data/train/IMG_0001-2_jpg.rf.92a333a1faf7221f955ccc344ddc1c91.jpg  \n",
      " extracting: data/train/IMG_0001-4_jpg.rf.8ec382489d0af254d192ec42666e982a.jpg  \n",
      " extracting: data/train/IMG_0001_jpg.rf.7a4664496bb452375ac63af3248c1833.jpg  \n",
      " extracting: data/train/IMG_0002-2_jpg.rf.499e6fac0546e9a947deef652651076a.jpg  \n",
      " extracting: data/train/IMG_0002-3_jpg.rf.d98c7fbb7b23e6958f1d153e55cc7ae6.jpg  \n",
      " extracting: data/train/IMG_0003-3_jpg.rf.968c107cf51b954d1e362bf4a6979f79.jpg  \n",
      " extracting: data/train/IMG_0003-4_jpg.rf.156c6fee1af2425a62a0068b8a9d7e56.jpg  \n",
      " extracting: data/train/IMG_0003-5_jpg.rf.e5686657583e95bb7ebb5f2694762215.jpg  \n",
      " extracting: data/train/IMG_0003_jpg.rf.5b4b7701006f967e6dbf74c801c5cc90.jpg  \n",
      " extracting: data/train/IMG_0004-2_jpg.rf.f83740e495475c38decfe6b151a69279.jpg  \n",
      " extracting: data/train/IMG_0004-3_jpg.rf.c972246299eb3e5734e584ff3cd1d097.jpg  \n",
      " extracting: data/train/IMG_0004-4_jpg.rf.ecfe5214a1099a7f34d694653c17f9b3.jpg  \n",
      " extracting: data/train/IMG_0004-5_jpg.rf.c7fc37d3743e1c2aba81ebc4ede4bcde.jpg  \n",
      " extracting: data/train/IMG_0004_jpg.rf.426913803a6a5fc801db1176eb63ef04.jpg  \n",
      " extracting: data/train/IMG_0005-2_jpg.rf.ede3bc29a40ded39c0ea68de6a28e5a6.jpg  \n",
      " extracting: data/train/IMG_0005-3_jpg.rf.6d838294ef888521232b172db7b3ef19.jpg  \n",
      " extracting: data/train/IMG_0005_jpg.rf.a8a9cbbb4d7c44e7ecba83ebce9f173d.jpg  \n",
      " extracting: data/train/IMG_0006-2_jpg.rf.a2c8d6201e3be4f26a786bcd0a345591.jpg  \n",
      " extracting: data/train/IMG_0006-4_jpg.rf.9b16dc6f600c1ac624c357aea464a0d2.jpg  \n",
      " extracting: data/train/IMG_0007-2_jpg.rf.c69a1c75ff7bba4af874f9d680675662.jpg  \n",
      " extracting: data/train/IMG_0007-3_jpg.rf.a52a74aa0ec4cd3f7e49741be765bac8.jpg  \n",
      " extracting: data/train/IMG_0007-4_jpg.rf.400116181e9dd624c8dbbe2d304386ce.jpg  \n",
      " extracting: data/train/IMG_0007-5_jpg.rf.9adc55bcb6186fa4ca765d8a2ed0c44d.jpg  \n",
      " extracting: data/train/IMG_0007_jpg.rf.f4c75b3d47af9d6d13081007ef17090d.jpg  \n",
      " extracting: data/train/IMG_0008-3_jpg.rf.9096317d49b44266ea25ef0a32a72f71.jpg  \n",
      " extracting: data/train/IMG_0008-4_jpg.rf.54d94ac728dba9635cd209cfe1e34426.jpg  \n",
      " extracting: data/train/IMG_0008_jpg.rf.9f30d3701b070b9ef262e4b89c42df3d.jpg  \n",
      " extracting: data/train/IMG_0009-2_jpg.rf.cc2edb4c033253a17445223b8c15b972.jpg  \n",
      " extracting: data/train/IMG_0009-3_jpg.rf.c49ec4906786d214290d471222f2c8f9.jpg  \n",
      " extracting: data/train/IMG_0010-2_jpg.rf.f290a0a524d23664a8296b2668a60c0e.jpg  \n",
      " extracting: data/train/IMG_0010-3_jpg.rf.5a607522eefdef99a906cba550b52e40.jpg  \n",
      " extracting: data/train/IMG_0010_jpg.rf.5ff96e759c9bbce3229c4e9a54000ef7.jpg  \n",
      " extracting: data/train/IMG_0011-2_jpg.rf.41a2f7226e6797a363866a36ac5dcce8.jpg  \n",
      " extracting: data/train/IMG_0011-3_jpg.rf.43be933ad1004d1f0c5995cb70583f92.jpg  \n",
      " extracting: data/train/IMG_0012-3_jpg.rf.429292d51453a9605e6798e6ba5af7ab.jpg  \n",
      " extracting: data/train/IMG_0012_jpg.rf.08291ffbc084fd7aa08dcf5cd999a57e.jpg  \n",
      " extracting: data/train/IMG_0013-2_jpg.rf.909034c339621c1be202d7e74a2bd34b.jpg  \n",
      " extracting: data/train/IMG_0013_jpg.rf.b607b184a9ed48f3fba3fa74187812cd.jpg  \n",
      " extracting: data/train/IMG_0014-2_jpg.rf.4bc6d852c149c7ae704644b0f843cd67.jpg  \n",
      " extracting: data/train/IMG_0015-3_jpg.rf.467f0c4a74205fedaca3fb49ce796354.jpg  \n",
      " extracting: data/train/IMG_0015_jpg.rf.eaad276159b1536bc5d51660b048a47f.jpg  \n",
      " extracting: data/train/IMG_0016-3_jpg.rf.4c92133c8e54fe6b22e59b41423eef5e.jpg  \n",
      " extracting: data/train/IMG_0016_jpg.rf.7edcf799bbbd75f54ac5991bcabba52b.jpg  \n",
      " extracting: data/train/IMG_0017-2_jpg.rf.737bea179b6aefd374016f8f790134a3.jpg  \n",
      " extracting: data/train/IMG_0017-3_jpg.rf.4118fba98f297561a7e07dee6ecb2df9.jpg  \n",
      " extracting: data/train/IMG_0017_jpg.rf.2e00fc287be838d3940f8daa9b05e576.jpg  \n",
      " extracting: data/train/IMG_0018-2_jpg.rf.a9e193c35e9290b61abb397e30ecd2af.jpg  \n",
      " extracting: data/train/IMG_0018-3_jpg.rf.9eb11483455a8e44803bcb6ae477dd87.jpg  \n",
      " extracting: data/train/IMG_0019-2_jpg.rf.ac4db5adef3be2679509a5e306f83f08.jpg  \n",
      " extracting: data/train/IMG_0019-3_jpg.rf.3323c0a8b60166c7fc33321c75f3de2e.jpg  \n",
      " extracting: data/train/IMG_0019_jpg.rf.8a073e42475de4302fc3aea284bf362c.jpg  \n",
      " extracting: data/train/IMG_0020-2_jpg.rf.84c5222df0a79082ff34bf4711343b6c.jpg  \n",
      " extracting: data/train/IMG_0020-3_jpg.rf.94840f3667fab783b1b0df3d5bc5d242.jpg  \n",
      " extracting: data/train/IMG_0021-2_jpg.rf.6eb3262933b0f6cefbab4d30b51a64a7.jpg  \n",
      " extracting: data/train/IMG_0021-3_jpg.rf.7765ba5a7d973ad878a06c23d36fd2fa.jpg  \n",
      " extracting: data/train/IMG_0021_jpg.rf.48a517e3588d6af27c14cfc4ab14ab39.jpg  \n",
      " extracting: data/train/IMG_0023-2_jpg.rf.6cb5f366cf8cbc9c19e8111775467c23.jpg  \n",
      " extracting: data/train/IMG_0023_jpg.rf.05b752088653b8d5cc761386885d47b0.jpg  \n",
      " extracting: data/train/IMG_0024-3_jpg.rf.44b61a27df5da0bfdb8a2756347f1450.jpg  \n",
      " extracting: data/train/IMG_0024_jpg.rf.331eb8910b791d129ea806caa53c4d6a.jpg  \n",
      " extracting: data/train/IMG_0025-2_jpg.rf.724855152cff07b81102d0ec49e86aaa.jpg  \n",
      " extracting: data/train/IMG_0026_jpg.rf.d0a637349935349f04e11f4949d946e0.jpg  \n",
      " extracting: data/train/IMG_0027-2_jpg.rf.5bb422b18401bebb1be2b8b46c5111fb.jpg  \n",
      " extracting: data/train/IMG_0028-2_jpg.rf.dccfaae827d8486329a96b0105fe1198.jpg  \n",
      " extracting: data/train/IMG_0029-2_jpg.rf.ab07441f10d4fd878f61b89f9f1dc100.jpg  \n",
      " extracting: data/train/IMG_0030_jpg.rf.5cbb64a9d108e374f5f0f7d9aa21350e.jpg  \n",
      " extracting: data/train/IMG_0031_jpg.rf.69776f607d4c2c229e8868ca8ffe51e6.jpg  \n",
      " extracting: data/train/IMG_0032-2_jpg.rf.868e7aa1ba410a03a29bb5843eec634e.jpg  \n",
      " extracting: data/train/IMG_0032_jpg.rf.325aa1d5c8871b81272f83a057bddffa.jpg  \n",
      " extracting: data/train/IMG_0033_jpg.rf.1e307c1e5cf9395916424a8e7de4d8f8.jpg  \n",
      " extracting: data/train/IMG_0034-2_jpg.rf.3f1c05a2af87b43b5a638c6c9f9da1f2.jpg  \n",
      " extracting: data/train/IMG_0034_jpg.rf.c3aa8be3b0b10fd07d1f955033638e38.jpg  \n",
      " extracting: data/train/IMG_0035-2_jpg.rf.d9a2eb7b7cdca572db2e8755fe13c9dd.jpg  \n",
      " extracting: data/train/IMG_0036_jpg.rf.ae6b2fd9f18c49f5bc7a2226d0ceaeb2.jpg  \n",
      " extracting: data/train/IMG_0037_jpg.rf.22cf8134262680abb2d0b44bf6d8cd14.jpg  \n",
      " extracting: data/train/IMG_0038_jpg.rf.aeb045016f06b0bd0b409a89b8a6cb52.jpg  \n",
      " extracting: data/train/IMG_0039-2_jpg.rf.beb49a17b6d7ace97ead15cfd17f0cb0.jpg  \n",
      " extracting: data/train/IMG_0039_jpg.rf.3928da3cca7337bbaf522e13824ce0b8.jpg  \n",
      " extracting: data/train/IMG_0040_jpg.rf.7e2c8a22a352d5053c1018a8031ed99e.jpg  \n",
      " extracting: data/train/IMG_0041-2_jpg.rf.33c4ba3b79681ee91b66cd36bf3d5e66.jpg  \n",
      " extracting: data/train/IMG_0041_jpg.rf.01135f85ac804bcce4ca7b75e35e53bd.jpg  \n",
      " extracting: data/train/IMG_0042_jpg.rf.98bee366312b8c8e1fbad64238aca115.jpg  \n",
      " extracting: data/train/IMG_0043_jpg.rf.d74655049aaade7345840fe918aa8449.jpg  \n",
      " extracting: data/train/IMG_0044_jpg.rf.2c9d18dc5622f082d283da7df5f05383.jpg  \n",
      " extracting: data/train/IMG_0045-2_jpg.rf.c795113b2e1444d30b22d07fc3c0363d.jpg  \n",
      " extracting: data/train/IMG_0046-2_jpg.rf.988650a5850f03bfee4956ae763d448f.jpg  \n",
      " extracting: data/train/IMG_0046_jpg.rf.56bc7109972be20ed14f7c322801b352.jpg  \n",
      " extracting: data/train/IMG_0047_jpg.rf.e79587db2bda5933feccf396e03d7184.jpg  \n",
      " extracting: data/train/IMG_0049-2_jpg.rf.6d8dd42e3d7f57a9c1d456e7ceb3a985.jpg  \n",
      " extracting: data/train/IMG_0049_jpg.rf.2364a7a49cf7d63c419370e1aa444661.jpg  \n",
      " extracting: data/train/IMG_0051-2_jpg.rf.feb817f525fb51440fae75612a7ac4ec.jpg  \n",
      " extracting: data/train/IMG_0051_jpg.rf.98f7287c2a7e0d749640051da4fe1641.jpg  \n",
      " extracting: data/train/IMG_0052_jpg.rf.376844547ce0e8954964d47d0e60de42.jpg  \n",
      " extracting: data/train/IMG_0053-2_jpg.rf.c89a19d9ae62b8ad4c89df2555d992a4.jpg  \n",
      " extracting: data/train/IMG_0054-2_jpg.rf.e4a5e78091e90a88853a972af3d28818.jpg  \n",
      " extracting: data/train/IMG_0054_jpg.rf.0b8c71b21159ed3a062e7e962520730b.jpg  \n",
      " extracting: data/train/IMG_0055-2_jpg.rf.50f186e108f098b6c76e8b7beaa355ce.jpg  \n",
      " extracting: data/train/IMG_0056_jpg.rf.ab3712ae8e3a48edfc65503be046b844.jpg  \n",
      " extracting: data/train/IMG_0057_jpg.rf.a70f88db3865279c4cc60342bf535aa6.jpg  \n",
      " extracting: data/train/IMG_0058_jpg.rf.6653104b6d21d55d3e3f5812245ca68d.jpg  \n",
      " extracting: data/train/IMG_0061_jpg.rf.8a62f528acf4d687b6cc49ba7ac78567.jpg  \n",
      " extracting: data/train/IMG_0062_jpg.rf.25975423bc1949a4b98bab869bb7ef52.jpg  \n",
      " extracting: data/train/IMG_0063_jpg.rf.f09d364365bf472ca16c7cecede484c7.jpg  \n",
      " extracting: data/train/IMG_0064_jpg.rf.44b8a49b28d477d807812153b7058160.jpg  \n",
      " extracting: data/train/IMG_0065_jpg.rf.b9ee8ac40a927dfb47cbe66880ef6afa.jpg  \n",
      " extracting: data/train/IMG_0067_jpg.rf.fab03d9c9e9d215d3fb24afe9ace6551.jpg  \n",
      " extracting: data/train/IMG_0068_jpg.rf.f13c3bcf1704ee3a5c935ffeb3f94627.jpg  \n",
      " extracting: data/train/IMG_0069_jpg.rf.aa5933f4c7200a437d3c507d566279b0.jpg  \n",
      " extracting: data/train/IMG_0070_jpg.rf.3fbd32179cc19fc49580a1d82cec260a.jpg  \n",
      " extracting: data/train/IMG_0071_jpg.rf.5d5c92fdbd1f560347cd577f756ded92.jpg  \n",
      " extracting: data/train/IMG_0072_jpg.rf.df0c3eb797a820d172378f9bbc4a8dcc.jpg  \n",
      " extracting: data/train/IMG_0073_jpg.rf.60869c9fade0f479cb95463a31d16e01.jpg  \n",
      " extracting: data/train/IMG_0074_jpg.rf.c5a98dcc56520a51dd14139d88a925ac.jpg  \n",
      " extracting: data/train/IMG_0076_jpg.rf.a37fd079253142f55afb33e0194f4115.jpg  \n",
      " extracting: data/train/IMG_0077_jpg.rf.198ed1c8a44228dd5079a223597468d5.jpg  \n",
      " extracting: data/train/IMG_0078_jpg.rf.96dad65039cb18bf04d6add14c2bc1ce.jpg  \n",
      " extracting: data/train/IMG_0079_jpg.rf.7bcc500a36e7e20cf3788765e7860a0d.jpg  \n",
      " extracting: data/train/IMG_0080_jpg.rf.d30de1d93b39252fc51524eacff245e7.jpg  \n",
      " extracting: data/train/IMG_0081_jpg.rf.556ae4d0f70607760c4647f192b4d526.jpg  \n",
      " extracting: data/train/IMG_0082_jpg.rf.6e77b362eae40879ec51d368c51947a8.jpg  \n",
      " extracting: data/train/IMG_0083_jpg.rf.e4f89dfb7e5454070c3610d99808befc.jpg  \n",
      " extracting: data/train/IMG_0084_jpg.rf.051cf5e9463ec96bf5c04044253c9270.jpg  \n",
      " extracting: data/train/IMG_0085_jpg.rf.f0959dbe7e345c9866a8d5f6e2712769.jpg  \n",
      " extracting: data/train/IMG_0087_jpg.rf.dbc923395f524295381af510813aa18e.jpg  \n",
      " extracting: data/train/IMG_0089_jpg.rf.d18a8b12f6aad7b2a7cec55bfbe925aa.jpg  \n",
      " extracting: data/train/IMG_0090_jpg.rf.6b093ae6e271dce1afb390f888274cd2.jpg  \n",
      " extracting: data/train/IMG_0091_jpg.rf.0baa87da245e74232a4d3edae11bec6c.jpg  \n",
      " extracting: data/train/IMG_0094_jpg.rf.73bcf2fc4488a2b50625cd261d8bcce8.jpg  \n",
      " extracting: data/train/IMG_0095_jpg.rf.3f832f26eaee3b5e6effb66d8346b2ea.jpg  \n",
      " extracting: data/train/IMG_0096_jpg.rf.2ec4fa2b39f1893bbdc6eb6ca3b84076.jpg  \n",
      " extracting: data/train/IMG_0097_jpg.rf.6fd22499e153ee125ffe012f83508524.jpg  \n",
      " extracting: data/train/IMG_0098_jpg.rf.1a47a7c6a6b30e76838e37146504dad6.jpg  \n",
      " extracting: data/train/IMG_0101_jpg.rf.be76bc00e33156138021a60906e97add.jpg  \n",
      " extracting: data/train/IMG_0102_jpg.rf.af08e45d9564c84a4a2f3ae4539634e8.jpg  \n",
      " extracting: data/train/IMG_0103_jpg.rf.2403597d854cb88e500c928364c3cbd4.jpg  \n",
      " extracting: data/train/IMG_0104_jpg.rf.b6c7f1cdf7efaadfda30e4683fa96eae.jpg  \n",
      " extracting: data/train/IMG_0105_jpg.rf.fbfcb7c8684a838836464f78b91a36bb.jpg  \n",
      " extracting: data/train/IMG_0107_jpg.rf.8aaed68a73acc5f7e79eeabdf618a2d6.jpg  \n",
      " extracting: data/train/IMG_0108_jpg.rf.78b8fd6d90ec8523dbc729b66ffa9ae9.jpg  \n",
      " extracting: data/train/IMG_0109_jpg.rf.a0403f1bd12bb117d4ef319f08f30803.jpg  \n",
      " extracting: data/train/IMG_0110_jpg.rf.782b6a502e3ed3ec82ae06dddc270776.jpg  \n",
      " extracting: data/train/IMG_0112_jpg.rf.d3f74e2e58e637974f05e352c8e83961.jpg  \n",
      " extracting: data/train/_annotations.coco.json  \n",
      "   creating: data/valid/\n",
      " extracting: data/valid/IMG_0001-3_jpg.rf.ee13d34ff95e225775966fb01125eb2b.jpg  \n",
      " extracting: data/valid/IMG_0002-5_jpg.rf.56699e00cfaa59de1aba8caffbd65a03.jpg  \n",
      " extracting: data/valid/IMG_0002_jpg.rf.050c23e8728217743cfe840a4b1e6457.jpg  \n",
      " extracting: data/valid/IMG_0003-2_jpg.rf.489304f8bfe48c8a5cc929846229a7d7.jpg  \n",
      " extracting: data/valid/IMG_0006-3_jpg.rf.3a40ea679a281f67ce4644083018eaef.jpg  \n",
      " extracting: data/valid/IMG_0006_jpg.rf.696bf26255849df25e6cab8771514442.jpg  \n",
      " extracting: data/valid/IMG_0008-2_jpg.rf.cf9f904f5015f83ec478fb635ddddf35.jpg  \n",
      " extracting: data/valid/IMG_0011_jpg.rf.df936c6d7e0070e332bab38e3ae99a4f.jpg  \n",
      " extracting: data/valid/IMG_0013-3_jpg.rf.cfd0e12d14027a54a5646b4bc0c740b4.jpg  \n",
      " extracting: data/valid/IMG_0014-3_jpg.rf.7f75739d1813f8aa07b6f69d408fd7d5.jpg  \n",
      " extracting: data/valid/IMG_0014_jpg.rf.38789b8d9e85d09facf10ce33effe5f7.jpg  \n",
      " extracting: data/valid/IMG_0015-2_jpg.rf.d7b6e17c06c114b7a2ff6400bba776f0.jpg  \n",
      " extracting: data/valid/IMG_0016-2_jpg.rf.98dbe4a5b27c5f6a942132e40b2ca42a.jpg  \n",
      " extracting: data/valid/IMG_0018_jpg.rf.6ab115ccccd17396d9263b4b59acea70.jpg  \n",
      " extracting: data/valid/IMG_0020_jpg.rf.d7f244e61b95736d6982a85842dc3143.jpg  \n",
      " extracting: data/valid/IMG_0022-2_jpg.rf.6b304fe736962a82c85ccccf45decf8d.jpg  \n",
      " extracting: data/valid/IMG_0022-3_jpg.rf.e1dd6443fa24f73676eb7ff2eef491a7.jpg  \n",
      " extracting: data/valid/IMG_0025_jpg.rf.d9a4a96560fa676f921d5bd66f78364e.jpg  \n",
      " extracting: data/valid/IMG_0026-2_jpg.rf.d421744924c3ed5f2cfc8a5e21ded6eb.jpg  \n",
      " extracting: data/valid/IMG_0028_jpg.rf.973fe362ba9c0aa1861f19addef990af.jpg  \n",
      " extracting: data/valid/IMG_0029_jpg.rf.4e85f1e549ee93209d10ddabc2c8d2e1.jpg  \n",
      " extracting: data/valid/IMG_0035_jpg.rf.0b55826d85aaac4230c32cba7d36cd08.jpg  \n",
      " extracting: data/valid/IMG_0036-2_jpg.rf.ca5dca0cd54a009646d05a6510be2c77.jpg  \n",
      " extracting: data/valid/IMG_0042-2_jpg.rf.81c74c6f1ec09bbd6ecc3a29fe8a271d.jpg  \n",
      " extracting: data/valid/IMG_0044-2_jpg.rf.28a9c6e00e37caca959f572a9ccf33d1.jpg  \n",
      " extracting: data/valid/IMG_0047-2_jpg.rf.9df4656c11fd7923d866b1acc12dcb9a.jpg  \n",
      " extracting: data/valid/IMG_0048-2_jpg.rf.5cbe59059909a3fc80709949964dc821.jpg  \n",
      " extracting: data/valid/IMG_0048_jpg.rf.4897490204c0325e8d3d59c1b951450d.jpg  \n",
      " extracting: data/valid/IMG_0050_jpg.rf.d07868f2154846dc44958cab39244525.jpg  \n",
      " extracting: data/valid/IMG_0052-2_jpg.rf.54a1145e8da22349c19298952fa2cd21.jpg  \n",
      " extracting: data/valid/IMG_0053_jpg.rf.dd8163fbf000cd70197da55c37ade43e.jpg  \n",
      " extracting: data/valid/IMG_0055_jpg.rf.2e9fa2043184ea0772fd63e77054c877.jpg  \n",
      " extracting: data/valid/IMG_0066_jpg.rf.9a569e26c315204431610e1c727e7bac.jpg  \n",
      " extracting: data/valid/IMG_0075_jpg.rf.ebe283d9562c6cb3344575b614702ea8.jpg  \n",
      " extracting: data/valid/IMG_0086_jpg.rf.872fae12816567049f5fdd63764959fe.jpg  \n",
      " extracting: data/valid/IMG_0088_jpg.rf.ce65d0e3710c4907a3f637072c52bc97.jpg  \n",
      " extracting: data/valid/IMG_0092_jpg.rf.ca94620a37eb3d5453e0cf3fb43ff5b1.jpg  \n",
      " extracting: data/valid/IMG_0099_jpg.rf.3a2f63e3614aa606bf1a43120f8d3c2c.jpg  \n",
      " extracting: data/valid/IMG_0100_jpg.rf.b60b37f72bba9f57303d97fcc7420fb6.jpg  \n",
      " extracting: data/valid/IMG_0111_jpg.rf.594e1af2c3c630f8bd37e3193c7d035c.jpg  \n",
      " extracting: data/valid/IMG_0116_jpg.rf.15d403024729eff82896584043dd2097.jpg  \n",
      " extracting: data/valid/_annotations.coco.json  \n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!unzip Thermal\\ Dogs\\ and\\ People.v6-raw-images_autoorient.coco.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/annotations/\n",
    "\n",
    "for subset in [\"train\", \"valid\", \"test\"]:\n",
    "    json_name = f\"instances_{subset}.json\"\n",
    "    !mkdir -p data/images/$subset/\n",
    "    !cp data/$subset/* data/images/$subset/\n",
    "    !mv data/images/$subset/_annotations.coco.json data/annotations/$json_name\n",
    "    !rm -rf data/$subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Workspace Path: otx-workspace-DETECTION\n",
      "[*] Load Model Template ID: Custom_Object_Detection_Gen3_ATSS\n",
      "[*] Load Model Name: ATSS\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "2023-04-24 12:34:52,825 | WARNING : Duplicate key is detected among bases [{'data', 'data_root_path'}]\n",
      "2023-04-24 12:34:52,828 | WARNING : Duplicate key is detected among bases [{'model'}]\n",
      "2023-04-24 12:34:52,828 | WARNING : Duplicate key is detected among bases [{'load_from', 'model', 'task', 'resume_from', 'checkpoint_config'}]\n",
      "In the CLI, Update ignore to false in model configuration.\n",
      "[*] \t- Updated: otx-workspace-DETECTION/model.py\n",
      "[*] \t- Updated: otx-workspace-DETECTION/data_pipeline.py\n",
      "[*] \t- Updated: otx-workspace-DETECTION/tile_pipeline.py\n",
      "[*] \t- Updated: otx-workspace-DETECTION/deployment.py\n",
      "[*] \t- Updated: otx-workspace-DETECTION/hpo_config.yaml\n",
      "[*] \t- Updated: otx-workspace-DETECTION/compression_config.json\n",
      "[*] Update data configuration file to: otx-workspace-DETECTION/data.yaml\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/sklearn/utils/multiclass.py:14: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/openvino/pyopenvino/__init__.py:10: FutureWarning: The module is private and following namespace `pyopenvino` will be removed in the future\n",
      "  warnings.warn(message=\"The module is private and following namespace \" \"`pyopenvino` will be removed in the future\", category=FutureWarning)\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/albumentations/augmentations/geometric/functional.py:7: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:14: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/openvino/tools/mo/middle/passes/convert_data_type.py:43: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  'bool': (np.bool, 'BOOL', 'boolean'),\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/defusedxml/__init__.py:30: DeprecationWarning: defusedxml.cElementTree is deprecated, import from defusedxml.ElementTree instead.\n",
      "  from . import cElementTree\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/openvino/tools/mo/utils/type_utils.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_map_cast = {np.bool: lambda x: bool_cast(x),\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/openvino/tools/mo/utils/type_utils.py:24: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.str: lambda x: np.str(x)}\n",
      "/home/vinnamki/otx/training_extensions/venv/lib/python3.8/site-packages/openvino/offline_transformations/__init__.py:10: FutureWarning: The module is private and following namespace `offline_transformations` will be removed in the future, use `openvino.runtime.passes` instead!\n",
      "  warnings.warn(\n",
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n",
      "2023-04-24 12:34:55,972 | INFO : train()\n",
      "2023-04-24 12:34:55,972 | INFO : init data cfg.\n",
      "2023-04-24 12:34:55,978 | INFO : Training seed was set to 5 w/ deterministic=False.\n",
      "2023-04-24 12:34:55,980 | INFO : Try to create a 0 size memory pool.\n",
      "2023-04-24 12:34:55,980 | INFO : initialized.\n",
      "2023-04-24 12:34:55,989 | INFO : configure!: training=True\n",
      "2023-04-24 12:34:55,991 | INFO : CUDA_VISIBLE_DEVICES = None\n",
      "2023-04-24 12:34:55,991 | INFO : configure_data()\n",
      "2023-04-24 12:34:55,997 | INFO : task config!!!!: training=True\n",
      "load checkpoint from http path: https://storage.openvinotoolkit.org/repositories/openvino_training_extensions/models/object_detection/v2/mobilenet_v2-atss.pth\n",
      "2023-04-24 12:34:56,013 | INFO : train!\n",
      "2023-04-24 12:34:56,013 | INFO : cfg.gpu_ids = range(0, 1), distributed = False\n",
      "2023-04-24 12:34:56,085 | INFO : Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]\n",
      "CUDA available: True\n",
      "GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 12.1, V12.1.66\n",
      "GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0\n",
      "PyTorch: 1.13.1+cu117\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.14.1+cu117\n",
      "OpenCV: 4.7.0\n",
      "MMCV: 1.7.0\n",
      "MMCV Compiler: GCC 9.3\n",
      "MMCV CUDA Compiler: 11.7\n",
      "MMDetection: 2.28.1+ff5be9f\n",
      "------------------------------------------------------------\n",
      "\n",
      "2023-04-24 12:34:56,104 - mmdet - WARNING - Init model mobilenetv2_w1, pretrained=True, models cache ~/.torch/models\n",
      "load checkpoint from http path: https://storage.openvinotoolkit.org/repositories/openvino_training_extensions/models/object_detection/v2/mobilenet_v2-atss.pth\n",
      "2023-04-24 12:34:56,269 | INFO : ----------------- CustomATSS.load_state_dict_pre_hook() called w/ prefix: \n",
      "2023-04-24 12:34:56,269 | INFO : [] -> ['dog', 'person'] ([-1, -1])\n",
      "2023-04-24 12:34:57,524 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2023-04-24 12:34:57,525 | INFO : Task Adaptation: [] => ['dog', 'person']\n",
      "2023-04-24 12:34:57,526 | INFO : - Efficient Mode: False\n",
      "2023-04-24 12:34:57,526 | INFO : - Sampler type: cls_incr\n",
      "2023-04-24 12:34:57,526 | INFO : - Sampler flag: False\n",
      "2023-04-24 12:34:57,527 - mmdet - INFO - load checkpoint from http path: https://storage.openvinotoolkit.org/repositories/openvino_training_extensions/models/object_detection/v2/mobilenet_v2-atss.pth\n",
      "2023-04-24 12:34:57,540 | INFO : ----------------- CustomATSS.load_state_dict_pre_hook() called w/ prefix: \n",
      "2023-04-24 12:34:57,540 | INFO : [] -> ['dog', 'person'] ([-1, -1])\n",
      "2023-04-24 12:34:57,561 - mmdet - INFO - Start running, host: vinnamki@vinnamki, work_dir: /home/vinnamki/otx/training_extensions/notebooks/otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:34:57,561 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) ReduceLROnPlateauLrUpdaterHook     \n",
      "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
      "(ABOVE_NORMAL) EMAHook                            \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) CancelInterfaceHook                \n",
      "(NORMAL      ) AdaptiveTrainSchedulingHook        \n",
      "(NORMAL      ) LoggerReplaceHook                  \n",
      "(LOW         ) EvalHook                           \n",
      "(71          ) OTXProgressHook                    \n",
      "(75          ) LazyEarlyStoppingHook              \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) OTXLoggerHook                      \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) ReduceLROnPlateauLrUpdaterHook     \n",
      "(ABOVE_NORMAL) EMAHook                            \n",
      "(NORMAL      ) TaskAdaptHook                      \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(71          ) OTXProgressHook                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) OTXLoggerHook                      \n",
      "(VERY_LOW    ) MemCacheHook                       \n",
      "(LOWEST      ) ForceTrainModeHook                 \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) ReduceLROnPlateauLrUpdaterHook     \n",
      "(NORMAL      ) AdaptiveTrainSchedulingHook        \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(71          ) OTXProgressHook                    \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
      "(ABOVE_NORMAL) EMAHook                            \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(71          ) OTXProgressHook                    \n",
      "(75          ) LazyEarlyStoppingHook              \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) OTXLoggerHook                      \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(ABOVE_NORMAL) EMAHook                            \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(71          ) OTXProgressHook                    \n",
      "(75          ) LazyEarlyStoppingHook              \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) OTXLoggerHook                      \n",
      "(VERY_LOW    ) MemCacheHook                       \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) TaskAdaptHook                      \n",
      "(LOW         ) IterTimerHook                      \n",
      "(71          ) OTXProgressHook                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) OTXLoggerHook                      \n",
      "(VERY_LOW    ) MemCacheHook                       \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(71          ) OTXProgressHook                    \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(71          ) OTXProgressHook                    \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(71          ) OTXProgressHook                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) OTXLoggerHook                      \n",
      "(VERY_LOW    ) MemCacheHook                       \n",
      " -------------------- \n",
      "after_run:\n",
      "(NORMAL      ) CancelInterfaceHook                \n",
      "(71          ) OTXProgressHook                    \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "2023-04-24 12:34:57,561 - mmdet - INFO - workflow: [('train', 1)], max: 200 epochs\n",
      "2023-04-24 12:34:57,567 - mmdet - INFO - Checkpoints will be saved to /home/vinnamki/otx/training_extensions/notebooks/otx-workspace-DETECTION/outputs/20230424_123451_train/logs by HardDiskBackend.\n",
      "2023-04-24 12:34:57,567 | INFO : cancel hook is initialized\n",
      "2023-04-24 12:34:57,567 | INFO : logger in the runner is replaced to the MPA logger\n",
      "[                                                  ] 0/41, elapsed: 0s, ETA:WARNING:nncf:You are using DataParallel, which may cause significant performance issues with dynamic graph building. Consider using distributed training (DistributedDataParallel) instead.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 16.6 task/s, elapsed: 2s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:35:00,254 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 0    | 0.000  | 0.000 |\n",
      "| person | 27  | 0    | 0.000  | 0.000 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.000 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:35:00,693 | INFO : Update LrUpdaterHook patience: 2 -> 2\n",
      "2023-04-24 12:35:00,693 | INFO : Update CheckpointHook interval: 1 -> 3\n",
      "2023-04-24 12:35:00,693 | INFO : Update EvalHook interval: 1 -> 3\n",
      "2023-04-24 12:35:00,693 | INFO : Update EarlyStoppingHook patience: 10 -> 4\n",
      "2023-04-24 12:35:04,418 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:04,419 | INFO : Epoch [1][17/17]\tlr: 4.000e-03, eta: 2:12:51, time: 0.401, data_time: 0.195, memory: 6390, current_iters: 16, loss_cls: 0.7717, loss_bbox: 0.2965, loss_centerness: 0.5941, loss: 1.6623, grad_norm: 7.4473\n",
      "2023-04-24 12:35:04,501 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:08,294 | WARNING : training progress 1%\n",
      "2023-04-24 12:35:08,294 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:08,295 | INFO : Epoch [2][17/17]\tlr: 4.000e-03, eta: 1:42:45, time: 0.222, data_time: 0.034, memory: 6390, current_iters: 33, loss_cls: 0.2998, loss_bbox: 0.2588, loss_centerness: 0.5879, loss: 1.1465, grad_norm: 5.9345\n",
      "2023-04-24 12:35:08,353 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:12,043 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:12,044 | INFO : Epoch [3][17/17]\tlr: 4.000e-03, eta: 1:31:48, time: 0.216, data_time: 0.034, memory: 6390, current_iters: 50, loss_cls: 0.2084, loss_bbox: 0.2420, loss_centerness: 0.5865, loss: 1.0369, grad_norm: 5.3208\n",
      "2023-04-24 12:35:12,097 | INFO : Saving checkpoint at 3 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 31.5 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:35:13,678 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 395  | 1.000  | 0.976 |\n",
      "| person | 27  | 433  | 1.000  | 0.867 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.921 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:35:13,814 | INFO : Now best checkpoint is saved as best_mAP_epoch_3.pth.\n",
      "2023-04-24 12:35:13,814 | INFO : Best mAP is 0.9212 at 3 epoch.\n",
      "2023-04-24 12:35:13,814 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:13,814 | INFO : Epoch(val) [3][41]\tAP50: 0.9210, mAP: 0.9212, current_iters: 51\n",
      "2023-04-24 12:35:13,815 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:13,827 | INFO : \n",
      "Best Score: 0.9212362170219421, Current Score: 0.9212362170219421, Patience: 2 Count: 0\n",
      "2023-04-24 12:35:17,497 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:17,497 | INFO : Epoch [4][17/17]\tlr: 4.000e-03, eta: 1:26:06, time: 0.216, data_time: 0.035, memory: 6390, current_iters: 67, loss_cls: 0.1535, loss_bbox: 0.2245, loss_centerness: 0.5832, loss: 0.9612, grad_norm: 4.5419\n",
      "2023-04-24 12:35:17,552 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:21,199 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:21,199 | INFO : Epoch [5][17/17]\tlr: 4.000e-03, eta: 1:22:24, time: 0.214, data_time: 0.035, memory: 6390, current_iters: 84, loss_cls: 0.1492, loss_bbox: 0.2101, loss_centerness: 0.5838, loss: 0.9430, grad_norm: 4.4024\n",
      "2023-04-24 12:35:21,253 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:24,900 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:24,900 | INFO : Epoch [6][17/17]\tlr: 4.000e-03, eta: 1:19:49, time: 0.214, data_time: 0.033, memory: 6390, current_iters: 101, loss_cls: 0.1304, loss_bbox: 0.1940, loss_centerness: 0.5839, loss: 0.9083, grad_norm: 4.0937\n",
      "2023-04-24 12:35:24,959 | INFO : Saving checkpoint at 6 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 31.8 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:35:26,529 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 191  | 1.000  | 0.994 |\n",
      "| person | 27  | 261  | 1.000  | 0.971 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.983 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:35:26,581 | INFO : The previous best checkpoint /home/vinnamki/otx/training_extensions/notebooks/otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_3.pth was removed\n",
      "2023-04-24 12:35:26,669 | INFO : Now best checkpoint is saved as best_mAP_epoch_6.pth.\n",
      "2023-04-24 12:35:26,669 | INFO : Best mAP is 0.9825 at 6 epoch.\n",
      "2023-04-24 12:35:26,669 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:26,669 | INFO : Epoch(val) [6][41]\tAP50: 0.9830, mAP: 0.9825, current_iters: 102\n",
      "2023-04-24 12:35:26,670 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:26,680 | INFO : \n",
      "Best Score: 0.9825177192687988, Current Score: 0.9825177192687988, Patience: 2 Count: 0\n",
      "2023-04-24 12:35:30,425 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:30,425 | INFO : Epoch [7][17/17]\tlr: 4.000e-03, eta: 1:18:10, time: 0.220, data_time: 0.034, memory: 6390, current_iters: 118, loss_cls: 0.1096, loss_bbox: 0.1917, loss_centerness: 0.5862, loss: 0.8875, grad_norm: 3.6414\n",
      "2023-04-24 12:35:30,484 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:34,163 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:34,163 | INFO : Epoch [8][17/17]\tlr: 4.000e-03, eta: 1:16:40, time: 0.215, data_time: 0.034, memory: 6390, current_iters: 135, loss_cls: 0.1219, loss_bbox: 0.1968, loss_centerness: 0.5867, loss: 0.9055, grad_norm: 4.2717\n",
      "2023-04-24 12:35:34,217 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:37,932 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:37,932 | INFO : Epoch [9][17/17]\tlr: 4.000e-03, eta: 1:15:29, time: 0.218, data_time: 0.034, memory: 6390, current_iters: 152, loss_cls: 0.1060, loss_bbox: 0.1668, loss_centerness: 0.5855, loss: 0.8583, grad_norm: 3.4230\n",
      "2023-04-24 12:35:37,992 | INFO : Saving checkpoint at 9 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 32.1 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:35:39,549 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 159  | 1.000  | 1.000 |\n",
      "| person | 27  | 163  | 1.000  | 0.948 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.974 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:35:39,596 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:39,596 | INFO : Epoch(val) [9][41]\tAP50: 0.9740, mAP: 0.9741, current_iters: 153\n",
      "2023-04-24 12:35:39,597 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:39,608 | INFO : \n",
      "Best Score: 0.9825177192687988, Current Score: 0.9741374254226685, Patience: 2 Count: 1\n",
      "2023-04-24 12:35:43,339 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:43,339 | INFO : Epoch [10][17/17]\tlr: 4.000e-03, eta: 1:14:31, time: 0.219, data_time: 0.035, memory: 6390, current_iters: 169, loss_cls: 0.1052, loss_bbox: 0.1768, loss_centerness: 0.5828, loss: 0.8648, grad_norm: 3.7991\n",
      "2023-04-24 12:35:43,399 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:47,049 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:47,049 | INFO : Epoch [11][17/17]\tlr: 4.000e-03, eta: 1:13:30, time: 0.214, data_time: 0.037, memory: 6390, current_iters: 186, loss_cls: 0.0959, loss_bbox: 0.1682, loss_centerness: 0.5846, loss: 0.8487, grad_norm: 3.6433\n",
      "2023-04-24 12:35:47,104 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:50,711 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:50,711 | INFO : Epoch [12][17/17]\tlr: 4.000e-03, eta: 1:12:32, time: 0.211, data_time: 0.033, memory: 6390, current_iters: 203, loss_cls: 0.1050, loss_bbox: 0.1679, loss_centerness: 0.5859, loss: 0.8587, grad_norm: 3.5915\n",
      "2023-04-24 12:35:50,771 | INFO : Saving checkpoint at 12 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 29.1 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:35:52,464 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 123  | 1.000  | 0.996 |\n",
      "| person | 27  | 194  | 1.000  | 0.946 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.971 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:35:52,512 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:52,512 | INFO : Epoch(val) [12][41]\tAP50: 0.9710, mAP: 0.9712, current_iters: 204\n",
      "2023-04-24 12:35:52,512 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:52,524 | INFO : \n",
      "Best Score: 0.9825177192687988, Current Score: 0.971245527267456, Patience: 2 Count: 2\n",
      "2023-04-24 12:35:52,524 | INFO : \n",
      "Drop LR from: 0.004, to: 0.0004\n",
      "2023-04-24 12:35:56,195 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:56,195 | INFO : Epoch [13][17/17]\tlr: 4.000e-04, eta: 1:11:46, time: 0.216, data_time: 0.035, memory: 6390, current_iters: 220, loss_cls: 0.0896, loss_bbox: 0.1487, loss_centerness: 0.5829, loss: 0.8212, grad_norm: 3.2967\n",
      "2023-04-24 12:35:56,255 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:35:59,878 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:35:59,878 | INFO : Epoch [14][17/17]\tlr: 4.000e-04, eta: 1:10:59, time: 0.212, data_time: 0.033, memory: 6390, current_iters: 237, loss_cls: 0.0881, loss_bbox: 0.1428, loss_centerness: 0.5818, loss: 0.8127, grad_norm: 3.4747\n",
      "2023-04-24 12:35:59,933 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:36:03,548 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:36:03,549 | INFO : Epoch [15][17/17]\tlr: 4.000e-04, eta: 1:10:15, time: 0.212, data_time: 0.034, memory: 6390, current_iters: 254, loss_cls: 0.0925, loss_bbox: 0.1493, loss_centerness: 0.5867, loss: 0.8285, grad_norm: 3.3262\n",
      "2023-04-24 12:36:03,603 | INFO : Saving checkpoint at 15 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 31.5 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:36:05,194 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 111  | 1.000  | 0.996 |\n",
      "| person | 27  | 148  | 0.963  | 0.942 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.969 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:36:05,241 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:36:05,242 | INFO : Epoch(val) [15][41]\tAP50: 0.9690, mAP: 0.9690, current_iters: 255\n",
      "2023-04-24 12:36:05,242 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:36:05,254 | INFO : \n",
      "Best Score: 0.9825177192687988, Current Score: 0.9689621925354004, Patience: 2 Count: 1\n",
      "2023-04-24 12:36:08,937 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:36:08,937 | INFO : Epoch [16][17/17]\tlr: 4.000e-04, eta: 1:09:39, time: 0.216, data_time: 0.035, memory: 6390, current_iters: 271, loss_cls: 0.0793, loss_bbox: 0.1361, loss_centerness: 0.5786, loss: 0.7940, grad_norm: 3.0750\n",
      "2023-04-24 12:36:08,991 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:36:12,669 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:36:12,669 | INFO : Epoch [17][17/17]\tlr: 4.000e-04, eta: 1:09:03, time: 0.215, data_time: 0.035, memory: 6390, current_iters: 288, loss_cls: 0.0776, loss_bbox: 0.1321, loss_centerness: 0.5844, loss: 0.7941, grad_norm: 2.9924\n",
      "2023-04-24 12:36:12,727 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:36:16,419 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:36:16,419 | INFO : Epoch [18][17/17]\tlr: 4.000e-04, eta: 1:08:30, time: 0.216, data_time: 0.034, memory: 6390, current_iters: 305, loss_cls: 0.0905, loss_bbox: 0.1419, loss_centerness: 0.5832, loss: 0.8156, grad_norm: 3.4134\n",
      "2023-04-24 12:36:16,474 | INFO : Saving checkpoint at 18 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 29.5 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "2023-04-24 12:36:18,148 | INFO : \n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 96   | 1.000  | 0.996 |\n",
      "| person | 27  | 145  | 0.963  | 0.949 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.973 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:36:18,218 | INFO : \n",
      "Early Stopping at :17 with best mAP: 0.9825177192687988\n",
      "2023-04-24 12:36:18,218 | INFO : Exp name: otx-workspace-DETECTION/outputs/20230424_123451_train/logs\n",
      "2023-04-24 12:36:18,218 | INFO : Epoch(val) [18][41]\tAP50: 0.9730, mAP: 0.9728, current_iters: 306\n",
      "2023-04-24 12:36:18,218 | INFO : MemCacheHandlerBase uses 0 / 0 (0.0%) memory pool and store 0 items.\n",
      "2023-04-24 12:36:19,235 | INFO : Training seed was set to 5 w/ deterministic=False.\n",
      "2023-04-24 12:36:19,237 | INFO : Try to create a 0 size memory pool.\n",
      "2023-04-24 12:36:19,237 | INFO : initialized.\n",
      "2023-04-24 12:36:19,240 | INFO : configure!: training=False\n",
      "2023-04-24 12:36:19,241 | INFO : CUDA_VISIBLE_DEVICES = None\n",
      "load checkpoint from local path: otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_6.pth\n",
      "2023-04-24 12:36:19,276 | INFO : configure_data()\n",
      "2023-04-24 12:36:19,278 | INFO : task config!!!!: training=False\n",
      "load checkpoint from local path: otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_6.pth\n",
      "2023-04-24 12:36:19,308 | INFO : infer!\n",
      "2023-04-24 12:36:19,310 - mmdet - WARNING - Init model mobilenetv2_w1, pretrained=True, models cache ~/.torch/models\n",
      "load checkpoint from local path: otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_6.pth\n",
      "2023-04-24 12:36:19,487 | INFO : ----------------- CustomATSS.load_state_dict_pre_hook() called w/ prefix: \n",
      "2023-04-24 12:36:19,487 | INFO : ['dog', 'person'] -> ['dog', 'person'] ([0, 1])\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: ema_backbone_features_init_block_conv_weight, ema_backbone_features_init_block_bn_weight, ema_backbone_features_init_block_bn_bias, ema_backbone_features_stage1_unit1_conv1_conv_weight, ema_backbone_features_stage1_unit1_conv1_bn_weight, ema_backbone_features_stage1_unit1_conv1_bn_bias, ema_backbone_features_stage1_unit1_conv2_conv_weight, ema_backbone_features_stage1_unit1_conv2_bn_weight, ema_backbone_features_stage1_unit1_conv2_bn_bias, ema_backbone_features_stage1_unit1_conv3_conv_weight, ema_backbone_features_stage1_unit1_conv3_bn_weight, ema_backbone_features_stage1_unit1_conv3_bn_bias, ema_backbone_features_stage2_unit1_conv1_conv_weight, ema_backbone_features_stage2_unit1_conv1_bn_weight, ema_backbone_features_stage2_unit1_conv1_bn_bias, ema_backbone_features_stage2_unit1_conv2_conv_weight, ema_backbone_features_stage2_unit1_conv2_bn_weight, ema_backbone_features_stage2_unit1_conv2_bn_bias, ema_backbone_features_stage2_unit1_conv3_conv_weight, ema_backbone_features_stage2_unit1_conv3_bn_weight, ema_backbone_features_stage2_unit1_conv3_bn_bias, ema_backbone_features_stage2_unit2_conv1_conv_weight, ema_backbone_features_stage2_unit2_conv1_bn_weight, ema_backbone_features_stage2_unit2_conv1_bn_bias, ema_backbone_features_stage2_unit2_conv2_conv_weight, ema_backbone_features_stage2_unit2_conv2_bn_weight, ema_backbone_features_stage2_unit2_conv2_bn_bias, ema_backbone_features_stage2_unit2_conv3_conv_weight, ema_backbone_features_stage2_unit2_conv3_bn_weight, ema_backbone_features_stage2_unit2_conv3_bn_bias, ema_backbone_features_stage3_unit1_conv1_conv_weight, ema_backbone_features_stage3_unit1_conv1_bn_weight, ema_backbone_features_stage3_unit1_conv1_bn_bias, ema_backbone_features_stage3_unit1_conv2_conv_weight, ema_backbone_features_stage3_unit1_conv2_bn_weight, ema_backbone_features_stage3_unit1_conv2_bn_bias, ema_backbone_features_stage3_unit1_conv3_conv_weight, ema_backbone_features_stage3_unit1_conv3_bn_weight, ema_backbone_features_stage3_unit1_conv3_bn_bias, ema_backbone_features_stage3_unit2_conv1_conv_weight, ema_backbone_features_stage3_unit2_conv1_bn_weight, ema_backbone_features_stage3_unit2_conv1_bn_bias, ema_backbone_features_stage3_unit2_conv2_conv_weight, ema_backbone_features_stage3_unit2_conv2_bn_weight, ema_backbone_features_stage3_unit2_conv2_bn_bias, ema_backbone_features_stage3_unit2_conv3_conv_weight, ema_backbone_features_stage3_unit2_conv3_bn_weight, ema_backbone_features_stage3_unit2_conv3_bn_bias, ema_backbone_features_stage3_unit3_conv1_conv_weight, ema_backbone_features_stage3_unit3_conv1_bn_weight, ema_backbone_features_stage3_unit3_conv1_bn_bias, ema_backbone_features_stage3_unit3_conv2_conv_weight, ema_backbone_features_stage3_unit3_conv2_bn_weight, ema_backbone_features_stage3_unit3_conv2_bn_bias, ema_backbone_features_stage3_unit3_conv3_conv_weight, ema_backbone_features_stage3_unit3_conv3_bn_weight, ema_backbone_features_stage3_unit3_conv3_bn_bias, ema_backbone_features_stage4_unit1_conv1_conv_weight, ema_backbone_features_stage4_unit1_conv1_bn_weight, ema_backbone_features_stage4_unit1_conv1_bn_bias, ema_backbone_features_stage4_unit1_conv2_conv_weight, ema_backbone_features_stage4_unit1_conv2_bn_weight, ema_backbone_features_stage4_unit1_conv2_bn_bias, ema_backbone_features_stage4_unit1_conv3_conv_weight, ema_backbone_features_stage4_unit1_conv3_bn_weight, ema_backbone_features_stage4_unit1_conv3_bn_bias, ema_backbone_features_stage4_unit2_conv1_conv_weight, ema_backbone_features_stage4_unit2_conv1_bn_weight, ema_backbone_features_stage4_unit2_conv1_bn_bias, ema_backbone_features_stage4_unit2_conv2_conv_weight, ema_backbone_features_stage4_unit2_conv2_bn_weight, ema_backbone_features_stage4_unit2_conv2_bn_bias, ema_backbone_features_stage4_unit2_conv3_conv_weight, ema_backbone_features_stage4_unit2_conv3_bn_weight, ema_backbone_features_stage4_unit2_conv3_bn_bias, ema_backbone_features_stage4_unit3_conv1_conv_weight, ema_backbone_features_stage4_unit3_conv1_bn_weight, ema_backbone_features_stage4_unit3_conv1_bn_bias, ema_backbone_features_stage4_unit3_conv2_conv_weight, ema_backbone_features_stage4_unit3_conv2_bn_weight, ema_backbone_features_stage4_unit3_conv2_bn_bias, ema_backbone_features_stage4_unit3_conv3_conv_weight, ema_backbone_features_stage4_unit3_conv3_bn_weight, ema_backbone_features_stage4_unit3_conv3_bn_bias, ema_backbone_features_stage4_unit4_conv1_conv_weight, ema_backbone_features_stage4_unit4_conv1_bn_weight, ema_backbone_features_stage4_unit4_conv1_bn_bias, ema_backbone_features_stage4_unit4_conv2_conv_weight, ema_backbone_features_stage4_unit4_conv2_bn_weight, ema_backbone_features_stage4_unit4_conv2_bn_bias, ema_backbone_features_stage4_unit4_conv3_conv_weight, ema_backbone_features_stage4_unit4_conv3_bn_weight, ema_backbone_features_stage4_unit4_conv3_bn_bias, ema_backbone_features_stage4_unit5_conv1_conv_weight, ema_backbone_features_stage4_unit5_conv1_bn_weight, ema_backbone_features_stage4_unit5_conv1_bn_bias, ema_backbone_features_stage4_unit5_conv2_conv_weight, ema_backbone_features_stage4_unit5_conv2_bn_weight, ema_backbone_features_stage4_unit5_conv2_bn_bias, ema_backbone_features_stage4_unit5_conv3_conv_weight, ema_backbone_features_stage4_unit5_conv3_bn_weight, ema_backbone_features_stage4_unit5_conv3_bn_bias, ema_backbone_features_stage4_unit6_conv1_conv_weight, ema_backbone_features_stage4_unit6_conv1_bn_weight, ema_backbone_features_stage4_unit6_conv1_bn_bias, ema_backbone_features_stage4_unit6_conv2_conv_weight, ema_backbone_features_stage4_unit6_conv2_bn_weight, ema_backbone_features_stage4_unit6_conv2_bn_bias, ema_backbone_features_stage4_unit6_conv3_conv_weight, ema_backbone_features_stage4_unit6_conv3_bn_weight, ema_backbone_features_stage4_unit6_conv3_bn_bias, ema_backbone_features_stage4_unit7_conv1_conv_weight, ema_backbone_features_stage4_unit7_conv1_bn_weight, ema_backbone_features_stage4_unit7_conv1_bn_bias, ema_backbone_features_stage4_unit7_conv2_conv_weight, ema_backbone_features_stage4_unit7_conv2_bn_weight, ema_backbone_features_stage4_unit7_conv2_bn_bias, ema_backbone_features_stage4_unit7_conv3_conv_weight, ema_backbone_features_stage4_unit7_conv3_bn_weight, ema_backbone_features_stage4_unit7_conv3_bn_bias, ema_backbone_features_stage5_unit1_conv1_conv_weight, ema_backbone_features_stage5_unit1_conv1_bn_weight, ema_backbone_features_stage5_unit1_conv1_bn_bias, ema_backbone_features_stage5_unit1_conv2_conv_weight, ema_backbone_features_stage5_unit1_conv2_bn_weight, ema_backbone_features_stage5_unit1_conv2_bn_bias, ema_backbone_features_stage5_unit1_conv3_conv_weight, ema_backbone_features_stage5_unit1_conv3_bn_weight, ema_backbone_features_stage5_unit1_conv3_bn_bias, ema_backbone_features_stage5_unit2_conv1_conv_weight, ema_backbone_features_stage5_unit2_conv1_bn_weight, ema_backbone_features_stage5_unit2_conv1_bn_bias, ema_backbone_features_stage5_unit2_conv2_conv_weight, ema_backbone_features_stage5_unit2_conv2_bn_weight, ema_backbone_features_stage5_unit2_conv2_bn_bias, ema_backbone_features_stage5_unit2_conv3_conv_weight, ema_backbone_features_stage5_unit2_conv3_bn_weight, ema_backbone_features_stage5_unit2_conv3_bn_bias, ema_backbone_features_stage5_unit3_conv1_conv_weight, ema_backbone_features_stage5_unit3_conv1_bn_weight, ema_backbone_features_stage5_unit3_conv1_bn_bias, ema_backbone_features_stage5_unit3_conv2_conv_weight, ema_backbone_features_stage5_unit3_conv2_bn_weight, ema_backbone_features_stage5_unit3_conv2_bn_bias, ema_backbone_features_stage5_unit3_conv3_conv_weight, ema_backbone_features_stage5_unit3_conv3_bn_weight, ema_backbone_features_stage5_unit3_conv3_bn_bias, ema_backbone_features_stage5_unit4_conv1_conv_weight, ema_backbone_features_stage5_unit4_conv1_bn_weight, ema_backbone_features_stage5_unit4_conv1_bn_bias, ema_backbone_features_stage5_unit4_conv2_conv_weight, ema_backbone_features_stage5_unit4_conv2_bn_weight, ema_backbone_features_stage5_unit4_conv2_bn_bias, ema_backbone_features_stage5_unit4_conv3_conv_weight, ema_backbone_features_stage5_unit4_conv3_bn_weight, ema_backbone_features_stage5_unit4_conv3_bn_bias, ema_neck_lateral_convs_0_conv_weight, ema_neck_lateral_convs_0_conv_bias, ema_neck_lateral_convs_1_conv_weight, ema_neck_lateral_convs_1_conv_bias, ema_neck_lateral_convs_2_conv_weight, ema_neck_lateral_convs_2_conv_bias, ema_neck_fpn_convs_0_conv_weight, ema_neck_fpn_convs_0_conv_bias, ema_neck_fpn_convs_1_conv_weight, ema_neck_fpn_convs_1_conv_bias, ema_neck_fpn_convs_2_conv_weight, ema_neck_fpn_convs_2_conv_bias, ema_neck_fpn_convs_3_conv_weight, ema_neck_fpn_convs_3_conv_bias, ema_neck_fpn_convs_4_conv_weight, ema_neck_fpn_convs_4_conv_bias, ema_bbox_head_cls_convs_0_conv_weight, ema_bbox_head_cls_convs_0_gn_weight, ema_bbox_head_cls_convs_0_gn_bias, ema_bbox_head_cls_convs_1_conv_weight, ema_bbox_head_cls_convs_1_gn_weight, ema_bbox_head_cls_convs_1_gn_bias, ema_bbox_head_cls_convs_2_conv_weight, ema_bbox_head_cls_convs_2_gn_weight, ema_bbox_head_cls_convs_2_gn_bias, ema_bbox_head_cls_convs_3_conv_weight, ema_bbox_head_cls_convs_3_gn_weight, ema_bbox_head_cls_convs_3_gn_bias, ema_bbox_head_reg_convs_0_conv_weight, ema_bbox_head_reg_convs_0_gn_weight, ema_bbox_head_reg_convs_0_gn_bias, ema_bbox_head_reg_convs_1_conv_weight, ema_bbox_head_reg_convs_1_gn_weight, ema_bbox_head_reg_convs_1_gn_bias, ema_bbox_head_reg_convs_2_conv_weight, ema_bbox_head_reg_convs_2_gn_weight, ema_bbox_head_reg_convs_2_gn_bias, ema_bbox_head_reg_convs_3_conv_weight, ema_bbox_head_reg_convs_3_gn_weight, ema_bbox_head_reg_convs_3_gn_bias, ema_bbox_head_atss_cls_weight, ema_bbox_head_atss_cls_bias, ema_bbox_head_atss_reg_weight, ema_bbox_head_atss_reg_bias, ema_bbox_head_atss_centerness_weight, ema_bbox_head_atss_centerness_bias, ema_bbox_head_scales_0_scale, ema_bbox_head_scales_1_scale, ema_bbox_head_scales_2_scale, ema_bbox_head_scales_3_scale, ema_bbox_head_scales_4_scale\n",
      "\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 36.2 task/s, elapsed: 1s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n",
      "\n",
      "+--------+-----+------+--------+-------+\n",
      "| class  | gts | dets | recall | ap    |\n",
      "+--------+-----+------+--------+-------+\n",
      "| dog    | 22  | 191  | 1.000  | 0.994 |\n",
      "| person | 27  | 262  | 1.000  | 0.971 |\n",
      "+--------+-----+------+--------+-------+\n",
      "| mAP    |     |      |        | 0.983 |\n",
      "+--------+-----+------+--------+-------+\n",
      "2023-04-24 12:36:20,936 | INFO : Adjusting the confidence threshold\n",
      "2023-04-24 12:36:20,976 | INFO : Setting confidence threshold to 0.4 based on results\n",
      "2023-04-24 12:36:20,977 | INFO : Final model performance: Performance(score: 0.9387755102040816, dashboard: (17 metric groups))\n",
      "2023-04-24 12:36:20,977 | INFO : called save_model\n",
      "2023-04-24 12:36:21,073 | INFO : train done.\n",
      "2023-04-24 12:36:21,089 | INFO : infer()\n",
      "2023-04-24 12:36:21,089 | INFO : Confidence threshold 0.4\n",
      "2023-04-24 12:36:21,093 | INFO : Training seed was set to 5 w/ deterministic=False.\n",
      "2023-04-24 12:36:21,096 | INFO : Try to create a 0 size memory pool.\n",
      "2023-04-24 12:36:21,096 | INFO : initialized.\n",
      "2023-04-24 12:36:21,099 | INFO : configure!: training=False\n",
      "2023-04-24 12:36:21,100 | INFO : CUDA_VISIBLE_DEVICES = None\n",
      "load checkpoint from local path: otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_6.pth\n",
      "2023-04-24 12:36:21,127 | INFO : configure_data()\n",
      "2023-04-24 12:36:21,128 | INFO : task config!!!!: training=False\n",
      "load checkpoint from local path: otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_6.pth\n",
      "2023-04-24 12:36:21,155 | INFO : infer!\n",
      "2023-04-24 12:36:21,156 - mmdet - WARNING - Init model mobilenetv2_w1, pretrained=True, models cache ~/.torch/models\n",
      "load checkpoint from local path: otx-workspace-DETECTION/outputs/20230424_123451_train/logs/best_mAP_epoch_6.pth\n",
      "2023-04-24 12:36:21,326 | INFO : ----------------- CustomATSS.load_state_dict_pre_hook() called w/ prefix: \n",
      "2023-04-24 12:36:21,326 | INFO : ['dog', 'person'] -> ['dog', 'person'] ([0, 1])\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: ema_backbone_features_init_block_conv_weight, ema_backbone_features_init_block_bn_weight, ema_backbone_features_init_block_bn_bias, ema_backbone_features_stage1_unit1_conv1_conv_weight, ema_backbone_features_stage1_unit1_conv1_bn_weight, ema_backbone_features_stage1_unit1_conv1_bn_bias, ema_backbone_features_stage1_unit1_conv2_conv_weight, ema_backbone_features_stage1_unit1_conv2_bn_weight, ema_backbone_features_stage1_unit1_conv2_bn_bias, ema_backbone_features_stage1_unit1_conv3_conv_weight, ema_backbone_features_stage1_unit1_conv3_bn_weight, ema_backbone_features_stage1_unit1_conv3_bn_bias, ema_backbone_features_stage2_unit1_conv1_conv_weight, ema_backbone_features_stage2_unit1_conv1_bn_weight, ema_backbone_features_stage2_unit1_conv1_bn_bias, ema_backbone_features_stage2_unit1_conv2_conv_weight, ema_backbone_features_stage2_unit1_conv2_bn_weight, ema_backbone_features_stage2_unit1_conv2_bn_bias, ema_backbone_features_stage2_unit1_conv3_conv_weight, ema_backbone_features_stage2_unit1_conv3_bn_weight, ema_backbone_features_stage2_unit1_conv3_bn_bias, ema_backbone_features_stage2_unit2_conv1_conv_weight, ema_backbone_features_stage2_unit2_conv1_bn_weight, ema_backbone_features_stage2_unit2_conv1_bn_bias, ema_backbone_features_stage2_unit2_conv2_conv_weight, ema_backbone_features_stage2_unit2_conv2_bn_weight, ema_backbone_features_stage2_unit2_conv2_bn_bias, ema_backbone_features_stage2_unit2_conv3_conv_weight, ema_backbone_features_stage2_unit2_conv3_bn_weight, ema_backbone_features_stage2_unit2_conv3_bn_bias, ema_backbone_features_stage3_unit1_conv1_conv_weight, ema_backbone_features_stage3_unit1_conv1_bn_weight, ema_backbone_features_stage3_unit1_conv1_bn_bias, ema_backbone_features_stage3_unit1_conv2_conv_weight, ema_backbone_features_stage3_unit1_conv2_bn_weight, ema_backbone_features_stage3_unit1_conv2_bn_bias, ema_backbone_features_stage3_unit1_conv3_conv_weight, ema_backbone_features_stage3_unit1_conv3_bn_weight, ema_backbone_features_stage3_unit1_conv3_bn_bias, ema_backbone_features_stage3_unit2_conv1_conv_weight, ema_backbone_features_stage3_unit2_conv1_bn_weight, ema_backbone_features_stage3_unit2_conv1_bn_bias, ema_backbone_features_stage3_unit2_conv2_conv_weight, ema_backbone_features_stage3_unit2_conv2_bn_weight, ema_backbone_features_stage3_unit2_conv2_bn_bias, ema_backbone_features_stage3_unit2_conv3_conv_weight, ema_backbone_features_stage3_unit2_conv3_bn_weight, ema_backbone_features_stage3_unit2_conv3_bn_bias, ema_backbone_features_stage3_unit3_conv1_conv_weight, ema_backbone_features_stage3_unit3_conv1_bn_weight, ema_backbone_features_stage3_unit3_conv1_bn_bias, ema_backbone_features_stage3_unit3_conv2_conv_weight, ema_backbone_features_stage3_unit3_conv2_bn_weight, ema_backbone_features_stage3_unit3_conv2_bn_bias, ema_backbone_features_stage3_unit3_conv3_conv_weight, ema_backbone_features_stage3_unit3_conv3_bn_weight, ema_backbone_features_stage3_unit3_conv3_bn_bias, ema_backbone_features_stage4_unit1_conv1_conv_weight, ema_backbone_features_stage4_unit1_conv1_bn_weight, ema_backbone_features_stage4_unit1_conv1_bn_bias, ema_backbone_features_stage4_unit1_conv2_conv_weight, ema_backbone_features_stage4_unit1_conv2_bn_weight, ema_backbone_features_stage4_unit1_conv2_bn_bias, ema_backbone_features_stage4_unit1_conv3_conv_weight, ema_backbone_features_stage4_unit1_conv3_bn_weight, ema_backbone_features_stage4_unit1_conv3_bn_bias, ema_backbone_features_stage4_unit2_conv1_conv_weight, ema_backbone_features_stage4_unit2_conv1_bn_weight, ema_backbone_features_stage4_unit2_conv1_bn_bias, ema_backbone_features_stage4_unit2_conv2_conv_weight, ema_backbone_features_stage4_unit2_conv2_bn_weight, ema_backbone_features_stage4_unit2_conv2_bn_bias, ema_backbone_features_stage4_unit2_conv3_conv_weight, ema_backbone_features_stage4_unit2_conv3_bn_weight, ema_backbone_features_stage4_unit2_conv3_bn_bias, ema_backbone_features_stage4_unit3_conv1_conv_weight, ema_backbone_features_stage4_unit3_conv1_bn_weight, ema_backbone_features_stage4_unit3_conv1_bn_bias, ema_backbone_features_stage4_unit3_conv2_conv_weight, ema_backbone_features_stage4_unit3_conv2_bn_weight, ema_backbone_features_stage4_unit3_conv2_bn_bias, ema_backbone_features_stage4_unit3_conv3_conv_weight, ema_backbone_features_stage4_unit3_conv3_bn_weight, ema_backbone_features_stage4_unit3_conv3_bn_bias, ema_backbone_features_stage4_unit4_conv1_conv_weight, ema_backbone_features_stage4_unit4_conv1_bn_weight, ema_backbone_features_stage4_unit4_conv1_bn_bias, ema_backbone_features_stage4_unit4_conv2_conv_weight, ema_backbone_features_stage4_unit4_conv2_bn_weight, ema_backbone_features_stage4_unit4_conv2_bn_bias, ema_backbone_features_stage4_unit4_conv3_conv_weight, ema_backbone_features_stage4_unit4_conv3_bn_weight, ema_backbone_features_stage4_unit4_conv3_bn_bias, ema_backbone_features_stage4_unit5_conv1_conv_weight, ema_backbone_features_stage4_unit5_conv1_bn_weight, ema_backbone_features_stage4_unit5_conv1_bn_bias, ema_backbone_features_stage4_unit5_conv2_conv_weight, ema_backbone_features_stage4_unit5_conv2_bn_weight, ema_backbone_features_stage4_unit5_conv2_bn_bias, ema_backbone_features_stage4_unit5_conv3_conv_weight, ema_backbone_features_stage4_unit5_conv3_bn_weight, ema_backbone_features_stage4_unit5_conv3_bn_bias, ema_backbone_features_stage4_unit6_conv1_conv_weight, ema_backbone_features_stage4_unit6_conv1_bn_weight, ema_backbone_features_stage4_unit6_conv1_bn_bias, ema_backbone_features_stage4_unit6_conv2_conv_weight, ema_backbone_features_stage4_unit6_conv2_bn_weight, ema_backbone_features_stage4_unit6_conv2_bn_bias, ema_backbone_features_stage4_unit6_conv3_conv_weight, ema_backbone_features_stage4_unit6_conv3_bn_weight, ema_backbone_features_stage4_unit6_conv3_bn_bias, ema_backbone_features_stage4_unit7_conv1_conv_weight, ema_backbone_features_stage4_unit7_conv1_bn_weight, ema_backbone_features_stage4_unit7_conv1_bn_bias, ema_backbone_features_stage4_unit7_conv2_conv_weight, ema_backbone_features_stage4_unit7_conv2_bn_weight, ema_backbone_features_stage4_unit7_conv2_bn_bias, ema_backbone_features_stage4_unit7_conv3_conv_weight, ema_backbone_features_stage4_unit7_conv3_bn_weight, ema_backbone_features_stage4_unit7_conv3_bn_bias, ema_backbone_features_stage5_unit1_conv1_conv_weight, ema_backbone_features_stage5_unit1_conv1_bn_weight, ema_backbone_features_stage5_unit1_conv1_bn_bias, ema_backbone_features_stage5_unit1_conv2_conv_weight, ema_backbone_features_stage5_unit1_conv2_bn_weight, ema_backbone_features_stage5_unit1_conv2_bn_bias, ema_backbone_features_stage5_unit1_conv3_conv_weight, ema_backbone_features_stage5_unit1_conv3_bn_weight, ema_backbone_features_stage5_unit1_conv3_bn_bias, ema_backbone_features_stage5_unit2_conv1_conv_weight, ema_backbone_features_stage5_unit2_conv1_bn_weight, ema_backbone_features_stage5_unit2_conv1_bn_bias, ema_backbone_features_stage5_unit2_conv2_conv_weight, ema_backbone_features_stage5_unit2_conv2_bn_weight, ema_backbone_features_stage5_unit2_conv2_bn_bias, ema_backbone_features_stage5_unit2_conv3_conv_weight, ema_backbone_features_stage5_unit2_conv3_bn_weight, ema_backbone_features_stage5_unit2_conv3_bn_bias, ema_backbone_features_stage5_unit3_conv1_conv_weight, ema_backbone_features_stage5_unit3_conv1_bn_weight, ema_backbone_features_stage5_unit3_conv1_bn_bias, ema_backbone_features_stage5_unit3_conv2_conv_weight, ema_backbone_features_stage5_unit3_conv2_bn_weight, ema_backbone_features_stage5_unit3_conv2_bn_bias, ema_backbone_features_stage5_unit3_conv3_conv_weight, ema_backbone_features_stage5_unit3_conv3_bn_weight, ema_backbone_features_stage5_unit3_conv3_bn_bias, ema_backbone_features_stage5_unit4_conv1_conv_weight, ema_backbone_features_stage5_unit4_conv1_bn_weight, ema_backbone_features_stage5_unit4_conv1_bn_bias, ema_backbone_features_stage5_unit4_conv2_conv_weight, ema_backbone_features_stage5_unit4_conv2_bn_weight, ema_backbone_features_stage5_unit4_conv2_bn_bias, ema_backbone_features_stage5_unit4_conv3_conv_weight, ema_backbone_features_stage5_unit4_conv3_bn_weight, ema_backbone_features_stage5_unit4_conv3_bn_bias, ema_neck_lateral_convs_0_conv_weight, ema_neck_lateral_convs_0_conv_bias, ema_neck_lateral_convs_1_conv_weight, ema_neck_lateral_convs_1_conv_bias, ema_neck_lateral_convs_2_conv_weight, ema_neck_lateral_convs_2_conv_bias, ema_neck_fpn_convs_0_conv_weight, ema_neck_fpn_convs_0_conv_bias, ema_neck_fpn_convs_1_conv_weight, ema_neck_fpn_convs_1_conv_bias, ema_neck_fpn_convs_2_conv_weight, ema_neck_fpn_convs_2_conv_bias, ema_neck_fpn_convs_3_conv_weight, ema_neck_fpn_convs_3_conv_bias, ema_neck_fpn_convs_4_conv_weight, ema_neck_fpn_convs_4_conv_bias, ema_bbox_head_cls_convs_0_conv_weight, ema_bbox_head_cls_convs_0_gn_weight, ema_bbox_head_cls_convs_0_gn_bias, ema_bbox_head_cls_convs_1_conv_weight, ema_bbox_head_cls_convs_1_gn_weight, ema_bbox_head_cls_convs_1_gn_bias, ema_bbox_head_cls_convs_2_conv_weight, ema_bbox_head_cls_convs_2_gn_weight, ema_bbox_head_cls_convs_2_gn_bias, ema_bbox_head_cls_convs_3_conv_weight, ema_bbox_head_cls_convs_3_gn_weight, ema_bbox_head_cls_convs_3_gn_bias, ema_bbox_head_reg_convs_0_conv_weight, ema_bbox_head_reg_convs_0_gn_weight, ema_bbox_head_reg_convs_0_gn_bias, ema_bbox_head_reg_convs_1_conv_weight, ema_bbox_head_reg_convs_1_gn_weight, ema_bbox_head_reg_convs_1_gn_bias, ema_bbox_head_reg_convs_2_conv_weight, ema_bbox_head_reg_convs_2_gn_weight, ema_bbox_head_reg_convs_2_gn_bias, ema_bbox_head_reg_convs_3_conv_weight, ema_bbox_head_reg_convs_3_gn_weight, ema_bbox_head_reg_convs_3_gn_bias, ema_bbox_head_atss_cls_weight, ema_bbox_head_atss_cls_bias, ema_bbox_head_atss_reg_weight, ema_bbox_head_atss_reg_bias, ema_bbox_head_atss_centerness_weight, ema_bbox_head_atss_centerness_bias, ema_bbox_head_scales_0_scale, ema_bbox_head_scales_1_scale, ema_bbox_head_scales_2_scale, ema_bbox_head_scales_3_scale, ema_bbox_head_scales_4_scale\n",
      "\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 41/41, 31.0 task/s, elapsed: 1s, ETA:     0s2023-04-24 12:36:22,750 | INFO : Inference completed\n",
      "2023-04-24 12:36:22,751 | INFO : called evaluate()\n",
      "2023-04-24 12:36:22,781 | INFO : F-measure after evaluation: 0.9387755102040816\n",
      "2023-04-24 12:36:22,781 | INFO : Evaluation completed\n",
      "Performance(score: 0.9387755102040816, dashboard: (1 metric groups))\n",
      "otx train time elapsed:  0:01:32.570374\n"
     ]
    }
   ],
   "source": [
    "!otx train Custom_Object_Detection_Gen3_ATSS --train-data-roots data/ --val-data-roots data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
